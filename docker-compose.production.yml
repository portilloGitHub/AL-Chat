version: '3.8'

# Production environment configuration for AL-Chat
# Usage: docker-compose -f docker-compose.production.yml up -d
# Note: This is typically integrated into main website's docker-compose.yml

services:
  al-chat-backend:
    build:
      context: ./Backend
      dockerfile: Dockerfile
    container_name: al-chat-backend-production
    image: al-chat-backend:production
    # No exposed ports - accessed via internal Docker network only
    environment:
      - FLASK_ENV=production
      - PORT=5000
      # In production, OpenAI API key comes from main website's auth middleware
      # Don't set OPENAI_API_KEY here - it's passed via flask.g
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      - AL_CHAT_LOG_DIR=/app/SessionLog
      - DEPLOYMENT_MODE=production
    volumes:
      # Production session logs - mount from main website's volume management
      - ./SessionLog/production:/app/SessionLog
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - al-chat-production-network
    labels:
      - "environment=production"
      - "service=al-chat-backend"

networks:
  al-chat-production-network:
    driver: bridge
    name: al-chat-production-network
